

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>lingvo.core.recurrent module &mdash; Lingvo  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="lingvo.core.retry module" href="lingvo.core.retry.html" />
    <link rel="prev" title="lingvo.core.quant_utils module" href="lingvo.core.quant_utils.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Lingvo
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="lingvo.html">lingvo package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="lingvo.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="lingvo.core.html">lingvo.core package</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="lingvo.core.html#subpackages">Subpackages</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="lingvo.core.html#submodules">Submodules</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="lingvo.tasks.html">lingvo.tasks package</a></li>
<li class="toctree-l3"><a class="reference internal" href="lingvo.tools.html">lingvo.tools package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="lingvo.html#submodules">Submodules</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Lingvo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
          <li><a href="lingvo.html">lingvo package</a> &raquo;</li>
        
          <li><a href="lingvo.core.html">lingvo.core package</a> &raquo;</li>
        
      <li>lingvo.core.recurrent module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/lingvo.core.recurrent.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-lingvo.core.recurrent">
<span id="lingvo-core-recurrent-module"></span><h1>lingvo.core.recurrent module<a class="headerlink" href="#module-lingvo.core.recurrent" title="Permalink to this headline">¶</a></h1>
<p>Recurrent neural nets.</p>
<p>The main interface of this module is Recurrent().
This expects the caller to describe the recurrent neural net by specifying:</p>
<blockquote>
<div><ul>
<li><p>theta: the “weights” each RNN uses.</p></li>
<li><p>state0: the initial state of each RNN.</p></li>
<li><p>cell_fn: A python function describing RNN cell. It must have the following
signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cell_fn</span><span class="p">:</span> <span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">state1</span><span class="p">,</span> <span class="n">extras</span><span class="p">)</span>
</pre></div>
</div>
<p>state1 is the next RNN state, extras are computed by cell_fn
and the library forwards extras to cell_fn’s gradient function.</p>
</li>
<li><p>cell_grad: An optional python function describing the backprop gradient
function for the RNN cell. It must have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cell_grad</span><span class="p">:</span> <span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">extras</span><span class="p">,</span> <span class="n">dstate1</span><span class="p">)</span> <span class="o">-&gt;</span>
    <span class="p">(</span><span class="n">dtheta</span><span class="p">,</span> <span class="n">dstate0</span><span class="p">,</span> <span class="n">dinputs</span><span class="p">)</span>
</pre></div>
</div>
<p>dstate1 is what the backprop algorithm provides representing
gradients of the final loss w.r.t. state1.</p>
</li>
</ul>
</div></blockquote>
<p>All of <code class="xref py py-obj docutils literal notranslate"><span class="pre">theta</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">state0</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">inputs</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">extras</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">dstate1</span></code> are
<a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> so that they can carry a bunch of tensors around.</p>
<p>Recurrent computes, roughly:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">state</span> <span class="o">=</span> <span class="n">state0</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">inputs</span><span class="s1">&#39; sequence length:</span>
  <span class="n">state</span> <span class="o">=</span> <span class="n">cell_fn</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:])</span>
  <span class="n">accumulate_state</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">state</span>
<span class="k">return</span> <span class="n">accumulate_state</span><span class="p">,</span> <span class="n">state</span>
</pre></div>
</div>
<p>The main advantage to using Recurrent instead of tf.while_loop is in
memory savings. In order to compute the gradient for cell_fn, a tf.while_loop
implementation will try to save all of the intermediate tensor values in the
forward pass. For long input sequences this can add up to a very large amount
of memory space.</p>
<p>Recurrent saves only the state output from cell_fn, not any of the intermediate
tensors generated within cell_fn. This saves lots of memory in the forward
pass, but there is a cost: we have to recompute those intermediate tensors
in the backward pass in order to compute the gradient. This recomputation
is why we require that cell_fn be stateless: Recurrent calls cell_fn both
in the forward pass and in the backward pass, and both of those invocations
need to be the same in order for training to work properly.</p>
<p>When using Recurrent, then, we need to store state for the whole training
sequence (in accumulate_state), as well as all of the intermediate tensors
for a single step of cell_fn. Without Recurrent, we would store all of the
intermediate tensors for all of the steps.</p>
<p>We prefer that all of the inputs to cell_fn be passed in using theta, state0,
or inputs. But sometimes you may have code with other inputs; for instance, this
cell_fn references tensor my_tensor, even though it was never passed in as an
input:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">my_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">cell_fn</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">inputs</span><span class="o">.</span><span class="n">input</span> <span class="o">*</span> <span class="n">my_tensor</span>
</pre></div>
</div>
<p>We say that my_tensor was implicitly captured by cell_fn. By default,
Recurrent doesn’t allow this, but you can change that behavior by setting the
allow_implicit_captures flag.</p>
<dl class="py class">
<dt id="lingvo.core.recurrent.DevicePair">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">DevicePair</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">send</span></em>, <em class="sig-param"><span class="n">recv</span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingvo.core.recurrent.DevicePair" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.7/library/stdtypes.html#tuple" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<dl class="py method">
<dt id="lingvo.core.recurrent.DevicePair._asdict">
<code class="sig-name descname">_asdict</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#lingvo.core.recurrent.DevicePair._asdict" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a new OrderedDict which maps field names to their values.</p>
</dd></dl>

<dl class="py attribute">
<dt id="lingvo.core.recurrent.DevicePair._fields">
<code class="sig-name descname">_fields</code><em class="property"> = ('send', 'recv')</em><a class="headerlink" href="#lingvo.core.recurrent.DevicePair._fields" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.recurrent.DevicePair._make">
<em class="property">classmethod </em><code class="sig-name descname">_make</code><span class="sig-paren">(</span><em class="sig-param">iterable</em>, <em class="sig-param">new=&lt;built-in method __new__ of type object at 0x9d43a0&gt;</em>, <em class="sig-param">len=&lt;built-in function len&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#lingvo.core.recurrent.DevicePair._make" title="Permalink to this definition">¶</a></dt>
<dd><p>Make a new DevicePair object from a sequence or iterable</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.recurrent.DevicePair._replace">
<code class="sig-name descname">_replace</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">kwds</span></em><span class="sig-paren">)</span><a class="headerlink" href="#lingvo.core.recurrent.DevicePair._replace" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a new DevicePair object replacing specified fields with new values</p>
</dd></dl>

<dl class="py attribute">
<dt id="lingvo.core.recurrent.DevicePair._source">
<code class="sig-name descname">_source</code><em class="property"> = &quot;from builtins import property as _property, tuple as _tuple\nfrom operator import itemgetter as _itemgetter\nfrom collections import OrderedDict\n\nclass DevicePair(tuple):\n    'DevicePair(send, recv)'\n\n    __slots__ = ()\n\n    _fields = ('send', 'recv')\n\n    def __new__(_cls, send, recv):\n        'Create new instance of DevicePair(send, recv)'\n        return _tuple.__new__(_cls, (send, recv))\n\n    &#64;classmethod\n    def _make(cls, iterable, new=tuple.__new__, len=len):\n        'Make a new DevicePair object from a sequence or iterable'\n        result = new(cls, iterable)\n        if len(result) != 2:\n            raise TypeError('Expected 2 arguments, got %d' % len(result))\n        return result\n\n    def _replace(_self, **kwds):\n        'Return a new DevicePair object replacing specified fields with new values'\n        result = _self._make(map(kwds.pop, ('send', 'recv'), _self))\n        if kwds:\n            raise ValueError('Got unexpected field names: %r' % list(kwds))\n        return result\n\n    def __repr__(self):\n        'Return a nicely formatted representation string'\n        return self.__class__.__name__ + '(send=%r, recv=%r)' % self\n\n    def _asdict(self):\n        'Return a new OrderedDict which maps field names to their values.'\n        return OrderedDict(zip(self._fields, self))\n\n    def __getnewargs__(self):\n        'Return self as a plain tuple.  Used by copy and pickle.'\n        return tuple(self)\n\n    send = _property(_itemgetter(0), doc='Alias for field number 0')\n\n    recv = _property(_itemgetter(1), doc='Alias for field number 1')\n\n&quot;</em><a class="headerlink" href="#lingvo.core.recurrent.DevicePair._source" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="lingvo.core.recurrent.DevicePair.recv">
<em class="property">property </em><code class="sig-name descname">recv</code><a class="headerlink" href="#lingvo.core.recurrent.DevicePair.recv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py method">
<dt id="lingvo.core.recurrent.DevicePair.send">
<em class="property">property </em><code class="sig-name descname">send</code><a class="headerlink" href="#lingvo.core.recurrent.DevicePair.send" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._AssertSameTensors">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_AssertSameTensors</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">list_a</span></em>, <em class="sig-param"><span class="n">list_b</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_AssertSameTensors"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._AssertSameTensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Asserts that two lists of tensors are the same tensors.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._Index">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_Index</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">nmap</span></em>, <em class="sig-param"><span class="n">index</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_Index"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._Index" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> with x[index, :] for each tensor x in nmap.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nmap</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors.</p></li>
<li><p><strong>index</strong> – A tf scalar integer. Performance is better if ‘index’ is on the host
memory.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors. For each key in nmap:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rets</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">nmap</span><span class="o">.</span><span class="n">key</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:]</span>
</pre></div>
</div>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._Update">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_Update</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">nmap_acc</span></em>, <em class="sig-param"><span class="n">nmap_x</span></em>, <em class="sig-param"><span class="n">t</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_Update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._Update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates t-th row in accumulators.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nmap_acc</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors. The accumulators.</p></li>
<li><p><strong>nmap_x</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors. The update values.</p></li>
<li><p><strong>t</strong> – A scalar integer. Performance is better if ‘t’ is on the device memory.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors. Say, ret is returned. For each key, we have:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ret</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">nmap_acc</span><span class="p">[</span><span class="n">key</span><span class="p">];</span>
<span class="n">ret</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">nmap_x</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
</pre></div>
</div>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._SeqLenDim">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_SeqLenDim</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">nmap</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_SeqLenDim"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._SeqLenDim" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the 0-th dim size of tensors in nmap.</p>
<p>This is the max sequence length according to the shape of the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>nmap</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors. Every tensor’s 0-th dim has the same size.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A scalar tensor which is the size of 0-th dim of every tensors in nmap.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent.FlattenPadding">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">FlattenPadding</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">padding</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#FlattenPadding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent.FlattenPadding" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns padding reduced to have only the time dimension.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._SeqPaddingLength">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_SeqPaddingLength</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs_nmap</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_SeqPaddingLength"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._SeqPaddingLength" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the lengths of paddings at the beginning and end of the sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inputs_nmap</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors that may have ‘padding’ Every
tensor’s 0-th dim has the same size.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>padding length at the beginning, padding length at the end</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._EmptyAcc">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_EmptyAcc</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">slen</span></em>, <em class="sig-param"><span class="n">nmap</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_EmptyAcc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._EmptyAcc" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a set of accumulators for tensors in nmap.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>slen</strong> – A scalar tensor.</p></li>
<li><p><strong>nmap</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> with the same keys as nmap. ret.key, a tensor, has the
same dtype as nmap.key. The tensor’s shape has 1 more dimension
than the tensor nmap.key. The extra 0-th dimension is of size
slen. E.g., if slen=10 and nmap.key’s shape is [3, 5], then,
ret.key’s shape is [10, 3, 5].</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._EmptyWithFixShape">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_EmptyWithFixShape</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">shape</span></em>, <em class="sig-param"><span class="n">nmap</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_EmptyWithFixShape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._EmptyWithFixShape" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a set of empty initialized tensors with fixed shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> – A list of integers to describe the output tensor shape.</p></li>
<li><p><strong>nmap</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> with the same keys as nmap. ret.key, a tensor, has the
same dtype as nmap.key, but with the fixed shape.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._EmptyLike">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_EmptyLike</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">nmap</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_EmptyLike"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._EmptyLike" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a set of empty initialized tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>nmap</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors. Each tensor has the same shape and dtype as
its corresponding tensor in nmap. And each tensor is initialized.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._Add">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_Add</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">nmap_x</span></em>, <em class="sig-param"><span class="n">nmap_y</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_Add"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._Add" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds tensors in nmap_x with respective tensors in nmap_y.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nmap_x</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors.</p></li>
<li><p><strong>nmap_y</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of tensors. ret.key = nmap_x.key + nmap_y.key for every key.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._ConvertNoneGradientToZeros">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_ConvertNoneGradientToZeros</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">xs</span></em>, <em class="sig-param"><span class="n">dxs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_ConvertNoneGradientToZeros"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._ConvertNoneGradientToZeros" title="Permalink to this definition">¶</a></dt>
<dd><p>Sanitize dxs so that None becomes zeros appropriately.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> – A list of tensors.</p></li>
<li><p><strong>dxs</strong> – A list of tensors. dxs[i] corresponds to xs[i]’s gradient.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> same as dxs with None replaced by a zero tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._TransformDType">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_TransformDType</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">nmap</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_TransformDType"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._TransformDType" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt id="lingvo.core.recurrent._Recurrent">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_Recurrent</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cell_fn</span></em>, <em class="sig-param"><span class="n">cell_grad</span></em>, <em class="sig-param"><span class="n">stop_fn</span></em>, <em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">state0</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">extras</span></em>, <em class="sig-param"><span class="n">cell_type</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">accumulator_layer</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">implicit_captures</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">unused_acc_state</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_Recurrent"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._Recurrent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.7/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A helper class to construct a recurrent neural net.</p>
<dl class="py method">
<dt id="lingvo.core.recurrent._Recurrent.Compute">
<code class="sig-name descname">Compute</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_Recurrent.Compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._Recurrent.Compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the computation.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._ReflectOnCellFn">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_ReflectOnCellFn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cell_fn</span></em>, <em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">state0</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">accumulator_layer</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">check_stateful_ops</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">allow_implicit_capture</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_ReflectOnCellFn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._ReflectOnCellFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Reflects on the cell_fn, applying asserts and returning needed info.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cell_fn</strong> – A python function that computes:
state1, extras = cell_fn(theta, state0, inputs[t, :])</p></li>
<li><p><strong>theta</strong> – weights. A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>.</p></li>
<li><p><strong>state0</strong> – initial state. A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>.</p></li>
<li><p><strong>inputs</strong> – inputs. A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>.</p></li>
<li><p><strong>accumulator_layer</strong> – Whether the cell function must be run in the context of
the given accumulator layer.</p></li>
<li><p><strong>check_stateful_ops</strong> – if True, raise a <a class="reference external" href="https://docs.python.org/3.7/library/exceptions.html#ValueError" title="(in Python v3.7)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ValueError</span></code></a> if cell_fn is stateful.</p></li>
<li><p><strong>allow_implicit_capture</strong> – Whether to allow the <code class="xref py py-obj docutils literal notranslate"><span class="pre">cell_fn</span></code> to implicitly capture
tensors.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of implicit captures that the cell_fn takes.</p>
</dd>
<dt class="field-odd">Raises</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3.7/library/exceptions.html#ValueError" title="(in Python v3.7)"><strong>ValueError</strong></a> – cell_fn is stateful.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._GetCellGrad">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_GetCellGrad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cell_fn</span></em>, <em class="sig-param"><span class="n">cell_grad</span></em>, <em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">state0</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">accumulator_layer</span></em>, <em class="sig-param"><span class="n">check_stateful_ops</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">allow_implicit_capture</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_GetCellGrad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._GetCellGrad" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the gradient function for cell_fn.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cell_fn</strong> – The recurrent neural net’s cell function.</p></li>
<li><p><strong>cell_grad</strong> – If not None, cell_fn’s gradient function.</p></li>
<li><p><strong>theta</strong> – weights. A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>.</p></li>
<li><p><strong>state0</strong> – initial state. A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>.</p></li>
<li><p><strong>inputs</strong> – inputs. A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>.</p></li>
<li><p><strong>accumulator_layer</strong> – Whether the cell function must be run in the context of
the given accumulator layer.</p></li>
<li><p><strong>check_stateful_ops</strong> – if True, raise a <a class="reference external" href="https://docs.python.org/3.7/library/exceptions.html#ValueError" title="(in Python v3.7)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ValueError</span></code></a> if cell_fn is stateful.</p></li>
<li><p><strong>allow_implicit_capture</strong> – Whether to allow the <code class="xref py py-obj docutils literal notranslate"><span class="pre">cell_fn</span></code> to implicitly capture
tensors.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>Returns (cell_grad, implicit_captures). The passed in cell_grad is returned
as-is if not None. Otherwise, assume cell_fn is a python function
representing the recurrent neural net’s cell function, i.e.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cell_fn</span><span class="p">:</span> <span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">state1</span><span class="p">,</span> <span class="n">extra</span><span class="p">)</span>
</pre></div>
</div>
<p>returns its default gradient python function, i.e.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cell_grad</span><span class="p">:</span> <span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">extras</span><span class="p">,</span> <span class="n">captured</span><span class="p">,</span> <span class="n">dstate1</span><span class="p">)</span> <span class="o">-&gt;</span>
    <span class="p">(</span><span class="n">dtheta</span><span class="p">,</span> <span class="n">dstate0</span><span class="p">,</span> <span class="n">dinputs</span><span class="p">)</span>
</pre></div>
</div>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._AugmentState">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_AugmentState</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">state0</span></em>, <em class="sig-param"><span class="n">accumulator_layer</span></em>, <em class="sig-param"><span class="n">allow_overwrite</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_AugmentState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._AugmentState" title="Permalink to this definition">¶</a></dt>
<dd><p>Augments state0 with additional state.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._WrapAccumulatorCellFn">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_WrapAccumulatorCellFn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">accumulator_layer</span></em>, <em class="sig-param"><span class="n">cell_fn</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_WrapAccumulatorCellFn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._WrapAccumulatorCellFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrap a cell_fn to propagate accumulators.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._WrapAccumulatorCellGradFn">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_WrapAccumulatorCellGradFn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">accumulator_layer</span></em>, <em class="sig-param"><span class="n">cell_grad</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_WrapAccumulatorCellGradFn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._WrapAccumulatorCellGradFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrap a cell grad function to disable accumulators.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._WrapCellFnWithStepSeed">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_WrapCellFnWithStepSeed</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cell_fn</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_WrapCellFnWithStepSeed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._WrapCellFnWithStepSeed" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrap a cell_fn to initialize the step seed.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._WrapCellGradFnWithStepSeed">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_WrapCellGradFnWithStepSeed</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cell_grad</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_WrapCellGradFnWithStepSeed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._WrapCellGradFnWithStepSeed" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrap a cell grad function to handle step seed in state.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._WrapCellFnWithSymbolValues">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_WrapCellFnWithSymbolValues</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cell_fn</span></em>, <em class="sig-param"><span class="n">symbol_to_tensor_map</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_WrapCellFnWithSymbolValues"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._WrapCellFnWithSymbolValues" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrap a cell_fn to propagate symbol values.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._WrapCellGradFnWithSymbolValues">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_WrapCellGradFnWithSymbolValues</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cell_grad</span></em>, <em class="sig-param"><span class="n">cell_fn</span></em>, <em class="sig-param"><span class="n">symbol_to_tensor_map</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_WrapCellGradFnWithSymbolValues"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._WrapCellGradFnWithSymbolValues" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrap a cell grad function to propagate symbol values.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._DecorateCellFn">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_DecorateCellFn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cell_fn</span></em>, <em class="sig-param"><span class="n">accumulator_layer</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_DecorateCellFn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._DecorateCellFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Decorates cell_fn with additional state information.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._DecorateCellGrad">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_DecorateCellGrad</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cell_grad</span></em>, <em class="sig-param"><span class="n">accumulator_layer</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_DecorateCellGrad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._DecorateCellGrad" title="Permalink to this definition">¶</a></dt>
<dd><p>Decorates cell_grad with additional state information.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._IsSingleTimeStep">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_IsSingleTimeStep</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">inputs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_IsSingleTimeStep"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._IsSingleTimeStep" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns True only if the time dimension of inputs is 1.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._RecurrentSingleTimeStep">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_RecurrentSingleTimeStep</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">state0</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">cell_fn</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_RecurrentSingleTimeStep"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._RecurrentSingleTimeStep" title="Permalink to this definition">¶</a></dt>
<dd><p>Short-cut for the single timestep without explicit cell_grad case.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent.Recurrent">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">Recurrent</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">state0</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">cell_fn</span></em>, <em class="sig-param"><span class="n">cell_grad</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">cell_type</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">stop_fn</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">extras</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">check_stateful_ops</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">accumulator_layer</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">allow_implicit_capture</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#Recurrent"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent.Recurrent" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute a recurrent neural net.</p>
<p>Roughly, <a class="reference internal" href="#lingvo.core.recurrent.Recurrent" title="lingvo.core.recurrent.Recurrent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Recurrent()</span></code></a> computes the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">state</span> <span class="o">=</span> <span class="n">state0</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">inputs</span><span class="s1">&#39; sequence length:</span>
  <span class="n">state</span> <span class="o">=</span> <span class="n">cell_fn</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:])</span>
  <span class="n">accumulate_state</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">state</span>
<span class="k">return</span> <span class="n">accumulate_state</span><span class="p">,</span> <span class="n">state</span>
</pre></div>
</div>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">theta</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">state</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">inputs</span></code> are all <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> objects.</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">inputs[t,</span> <span class="pre">:]</span></code> means taking a slice out from every tensor in the
<a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> <code class="xref py py-obj docutils literal notranslate"><span class="pre">inputs</span></code>.</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">accumulate_state[t,</span> <span class="pre">:]</span> <span class="pre">=</span> <span class="pre">state</span></code> means that we stash every tensor in
<code class="xref py py-obj docutils literal notranslate"><span class="pre">state</span></code> into a slice of the corresponding tensor in
<code class="xref py py-obj docutils literal notranslate"><span class="pre">accumulate_state</span></code>.</p>
<p><code class="xref py py-obj docutils literal notranslate"><span class="pre">cell_fn</span></code> is a python callable computing (building up a TensorFlow
graph) the recurrent neural network’s one forward step. <code class="xref py py-obj docutils literal notranslate"><span class="pre">cell_fn</span></code> must not
contain any stateful ops. Two calls of <code class="xref py py-obj docutils literal notranslate"><span class="pre">cell_fn</span></code> must describe two identical
computations.</p>
<p>By construction, <a class="reference internal" href="#lingvo.core.recurrent.Recurrent" title="lingvo.core.recurrent.Recurrent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Recurrent()</span></code></a>’s backward computation does not access
any intermediate values computed by <code class="xref py py-obj docutils literal notranslate"><span class="pre">cell_fn</span></code> during forward
computation. We may extend <a class="reference internal" href="#lingvo.core.recurrent.Recurrent" title="lingvo.core.recurrent.Recurrent"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Recurrent()</span></code></a> to support that by taking a
customized backward function of <code class="xref py py-obj docutils literal notranslate"><span class="pre">cell_fn</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>theta</strong> – weights. A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>.</p></li>
<li><p><strong>state0</strong> – initial state. A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>.</p></li>
<li><p><strong>inputs</strong> – inputs. A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a>.</p></li>
<li><p><strong>cell_fn</strong> – <dl class="simple">
<dt>A python function which computes::</dt><dd><p>state1, extras = cell_fn(theta, state0, inputs[t, :])</p>
</dd>
</dl>
</p></li>
<li><p><strong>cell_grad</strong> – <dl class="simple">
<dt>A python function which computes::</dt><dd><dl class="simple">
<dt>dtheta, dstate0, dinputs[t, :], dcaptured = cell_grad(</dt><dd><dl class="simple">
<dt>theta, state0, inputs[t, :], extras, dstate1)  If there are no</dt><dd><p>captured tensors in <code class="xref py py-obj docutils literal notranslate"><span class="pre">cell_fn</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">dcaptured</span></code> can be returned as
None. Captured tensors with custom <code class="xref py py-obj docutils literal notranslate"><span class="pre">cell_grad</span></code> is currently
unsupported so this return value is reserved for future expansion.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</p></li>
<li><p><strong>cell_type</strong> – Cell name to be used.</p></li>
<li><p><strong>stop_fn</strong> – If not None, a python function which computes::  should_stop =
stop_fn(t, theta, state0)  The function determines whether the recurrent
loop should terminate.</p></li>
<li><p><strong>extras</strong> – A <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> of Tensors. The 2nd return value of every invocation
of <code class="xref py py-obj docutils literal notranslate"><span class="pre">cell_fn</span></code> is a <a class="reference internal" href="lingvo.core.py_utils.html#lingvo.core.py_utils.NestedMap" title="lingvo.core.py_utils.NestedMap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NestedMap</span></code></a> with matching keys and shapes of <code class="xref py py-obj docutils literal notranslate"><span class="pre">extras</span></code>.</p></li>
<li><p><strong>check_stateful_ops</strong> – if True, raise a <a class="reference external" href="https://docs.python.org/3.7/library/exceptions.html#ValueError" title="(in Python v3.7)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ValueError</span></code></a> if <code class="xref py py-obj docutils literal notranslate"><span class="pre">cell_fn</span></code> is stateful.</p></li>
<li><p><strong>accumulator_layer</strong> – If provided, then accumulators on this layer will be
managed such that they carry to the final state in <code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code> and are
disabled for gradients. Uses the state key <code class="xref py py-obj docutils literal notranslate"><span class="pre">accumulators</span></code>.</p></li>
<li><p><strong>allow_implicit_capture</strong> – Whether to allow the <code class="xref py py-obj docutils literal notranslate"><span class="pre">cell_fn</span></code> to implicitly capture
tensors. Only allowed if an explicit <code class="xref py py-obj docutils literal notranslate"><span class="pre">cell_grad</span></code> is not given.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">accumulate_state</span></code> and the final state.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="lingvo.core.recurrent._Link">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_Link</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">t</span></em>, <em class="sig-param"><span class="n">dpair</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_Link"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._Link" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.7/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>A link is a pair of channels.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._CreateLinks">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_CreateLinks</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">nmap</span></em>, <em class="sig-param"><span class="n">dpair</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_CreateLinks"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._CreateLinks" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates links between the send/recv devices for every tensor in nmap.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._Join">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_Join</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">nmap_x</span></em>, <em class="sig-param"><span class="n">nmap_y</span></em>, <em class="sig-param"><span class="n">fn</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_Join"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._Join" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt id="lingvo.core.recurrent._Input">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_Input</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cell_fn</span></em>, <em class="sig-param"><span class="n">cell_out</span></em>, <em class="sig-param"><span class="n">cell_grad</span></em>, <em class="sig-param"><span class="n">cell_out_grad</span></em>, <em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">state0</span></em>, <em class="sig-param"><span class="n">accumulator_layer</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">extras</span></em>, <em class="sig-param"><span class="n">out_links</span></em>, <em class="sig-param"><span class="n">unused_acc_state</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_Input"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._Input" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.7/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Input layers.</p>
<dl class="py method">
<dt id="lingvo.core.recurrent._Input.Compute">
<code class="sig-name descname">Compute</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_Input.Compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._Input.Compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the input layer.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.recurrent._Middle">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_Middle</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cell_fn</span></em>, <em class="sig-param"><span class="n">cell_out</span></em>, <em class="sig-param"><span class="n">cell_grad</span></em>, <em class="sig-param"><span class="n">cell_out_grad</span></em>, <em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">state0</span></em>, <em class="sig-param"><span class="n">accumulator_layer</span></em>, <em class="sig-param"><span class="n">in_links</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">slen_dim</span></em>, <em class="sig-param"><span class="n">per_step_inputs</span></em>, <em class="sig-param"><span class="n">extras</span></em>, <em class="sig-param"><span class="n">out_links</span></em>, <em class="sig-param"><span class="n">unused_acc_state</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_Middle"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._Middle" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.7/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Middle layers.</p>
<dl class="py method">
<dt id="lingvo.core.recurrent._Middle.Compute">
<code class="sig-name descname">Compute</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_Middle.Compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._Middle.Compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the middle layer.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="lingvo.core.recurrent._Output">
<em class="property">class </em><code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_Output</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cell_fn</span></em>, <em class="sig-param"><span class="n">cell_grad</span></em>, <em class="sig-param"><span class="n">theta</span></em>, <em class="sig-param"><span class="n">state0</span></em>, <em class="sig-param"><span class="n">accumulator_layer</span></em>, <em class="sig-param"><span class="n">in_links</span></em>, <em class="sig-param"><span class="n">padding</span></em>, <em class="sig-param"><span class="n">slen_dim</span></em>, <em class="sig-param"><span class="n">per_step_inputs</span></em>, <em class="sig-param"><span class="n">extras</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_Output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._Output" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3.7/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Output layers.</p>
<dl class="py method">
<dt id="lingvo.core.recurrent._Output.Compute">
<code class="sig-name descname">Compute</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_Output.Compute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._Output.Compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the output layer.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent._DependsOn">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">_DependsOn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">xs</span></em>, <em class="sig-param"><span class="n">ys</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#_DependsOn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent._DependsOn" title="Permalink to this definition">¶</a></dt>
<dd><p>Every x in xs should depend on every y in ys via a data edge.</p>
</dd></dl>

<dl class="py function">
<dt id="lingvo.core.recurrent.StackedRecurrent">
<code class="sig-prename descclassname">lingvo.core.recurrent.</code><code class="sig-name descname">StackedRecurrent</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">devices</span></em>, <em class="sig-param"><span class="n">cell_fns</span></em>, <em class="sig-param"><span class="n">cell_grads</span></em>, <em class="sig-param"><span class="n">cell_outs</span></em>, <em class="sig-param"><span class="n">cell_out_grads</span></em>, <em class="sig-param"><span class="n">thetas</span></em>, <em class="sig-param"><span class="n">init_states</span></em>, <em class="sig-param"><span class="n">inputs</span></em>, <em class="sig-param"><span class="n">accumulator_layers</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">unused_acc_state</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/lingvo/core/recurrent.html#StackedRecurrent"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#lingvo.core.recurrent.StackedRecurrent" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes stacked recurrent neural nets placed on various devices.</p>
<p>Conceptually, StackedRecurrent() computes the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">cell_fn</span><span class="p">,</span> <span class="n">cell_out</span><span class="p">,</span> <span class="n">cell_grad</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
  <span class="p">(</span><span class="n">devices</span><span class="p">,</span> <span class="n">cell_fns</span><span class="p">,</span> <span class="n">cell_outs</span><span class="p">,</span> <span class="n">cell_grads</span><span class="p">,</span> <span class="n">thetas</span><span class="p">,</span> <span class="n">init_states</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">):</span>
      <span class="n">state1</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">Recurrent</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">state0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">cell_fn</span><span class="p">,</span> <span class="n">cell_grad</span><span class="p">)</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">cell_out</span><span class="p">(</span><span class="n">state1</span><span class="p">)</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">outputs</span>  <span class="c1"># Next layer&#39;s input is this layer&#39;s output</span>
<span class="k">return</span> <span class="n">outputs</span>
</pre></div>
</div>
<p>The only difference is that StackedRecurrent implements a model parallelism
so that all layers computation can happen concurrently.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>devices</strong> – A list of N tensorflow device names.</p></li>
<li><p><strong>cell_fns</strong> – If a list of N recurrent cell function, cell_fns[i] must meet the
same requirement as Recurrent() requires its cell_fn argument.  Otherwise,
applies to all layers.</p></li>
<li><p><strong>cell_grads</strong> – If a list of N recurrent cell gradient function, cell_grads[i]
must meet the same requirement as Recurrent() requires its cell_grad
argument.  Otherwise, applies to all layers.</p></li>
<li><p><strong>cell_outs</strong> – If a list of N function, cell_outs[i] takes the state computed by
cell_fns[i] and returns the input for the next layer. These functions are
expected to be simple and just do renaming of fields.  Otherwise, applies
to all layers.</p></li>
<li><p><strong>cell_out_grads</strong> – If a list of N function, cell_out_grads[i] is often the
reverse of cell_outs[i]. Otherwise, applies to all layers.</p></li>
<li><p><strong>thetas</strong> – A list of N weights NestedMap. thetas[i] must meet the same
requirement as Recurrent() requires its theta argument.</p></li>
<li><p><strong>init_states</strong> – A list of N initial state NestedMap. init_states[i] must meet
the same requirement as Recurrent() requires its state0 argument.</p></li>
<li><p><strong>inputs</strong> – Inputs to the 1st layer of the stacked recurrent neural nets.  A
NestedMap.</p></li>
<li><p><strong>accumulator_layers</strong> – A list of layers whose accumulators will be managed such
that they carry to the output state in <code class="xref py py-obj docutils literal notranslate"><span class="pre">FProp</span></code> and are disabled for
gradients. Uses the state key <code class="xref py py-obj docutils literal notranslate"><span class="pre">accumulators</span></code>.  Default to None where no
accumulator values will be carried.</p></li>
<li><p><strong>unused_acc_state</strong> – If True, we shink all the layer’s acc_state to [num_ts]
except the last layer(_Output).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p>The last layer’s output (accumulated states).</p></li>
<li><p>The list of final state NestedMap. One for each layer.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple (output, states)</p>
</dd>
</dl>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="lingvo.core.retry.html" class="btn btn-neutral float-right" title="lingvo.core.retry module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="lingvo.core.quant_utils.html" class="btn btn-neutral float-left" title="lingvo.core.quant_utils module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>